{"posts":[{"title":"Spark基础环境配置","text":"安装Java Development Kit (JDK)Spark需要Java运行时环境（JRE）或Java开发工具包（JDK）。你可以通过以下命令来安装OpenJDK。在Ubuntu上：sudo apt updatesudo apt install openjdk-8-jdk -y验证安装：java -version 下载并安装HadoopSpark可以与Hadoop集成以处理大数据集。首先下载Hadoop二进制文件。下载Hadoop：wget https://downloads.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gztar xzf hadoop-3.3.1.tar.gzsudo mv hadoop-3.3.1 /usr/local/hadoop配置Hadoop：编辑/usr/local/hadoop/etc/hadoop/core-site.xmlconfiguration&gt; property&gt; name&gt;fs.defaultFS/name&gt; value&gt;hdfs://localhost:9000/value&gt;/property&gt;/configuration&gt;编辑/usr/local/hadoop/etc/hadoop/hdfs-site.xmlconfiguration&gt; property&gt; name&gt;dfs.replication/name&gt; value&gt;1/value&gt; /property&gt;/configuration&gt;初始化HDFS：/usr/local/hadoop/bin/hdfs namenode -format启动Hadoop：start-dfs.sh验证Hadoop是否正常运行：jps你应该能看到NameNode, DataNode, SecondaryNameNode进程。 下载并安装ZookeeperZookeeper用于管理集群状态。首先下载Zookeeper二进制文件。下载Zookeeper：wget https://downloads.apache.org/zookeeper/stable/apache-zookeeper-3.7.0-bin.tar.gztar xzf apache-zookeeper-3.7.0-bin.tar.gzsudo mv apache-zookeeper-3.7.0-bin /usr/local/zookeeper创建数据目录：sudo mkdir /var/lib/zookeeperecho “1” | sudo tee /var/lib/zookeeper/myid配置Zookeeper：编辑/usr/local/zookeeper/conf/zoo.cfg:propertiestickTime=2000dataDir=/var/lib/zookeeperclientPort=2181启动Zookeeper：/usr/local/zookeeper/bin/zkServer.sh start验证Zookeeper是否正常运行：/usr/local/zookeeper/bin/zkServer.sh status 下载并安装Apache Spark最后，下载并安装Apache Spark。下载Spark：wget https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgztar xzf spark-3.1.2-bin-hadoop3.2.tgzsudo mv spark-3.1.2-bin-hadoop3.2 /usr/local/spark配置Spark：编辑/usr/local/spark/conf/spark-env.sh:export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoopexport SPARK_WORKER_CORES=2export SPARK_WORKER_MEMORY=2gexport SPARK_MASTER_HOST=localhostexport SPARK_MASTER_PORT=7077启动Spark Master服务：/usr/local/spark/sbin/start-master.sh启动Spark Worker服务：/usr/local/spark/sbin/start-slave.sh spark://localhost:7077验证Spark是否正常运行：http://localhost:8080/打开上述URL应该可以看到Spark的Web UI。至此，你已经成功配置了Spark的基本环境，包括JDK、Hadoop和Zookeeper。接下来你可以开始编写和运行Spark应用程序了。","link":"/2025/06/12/Spark%20local&%20stand-alone%E9%85%8D%E7%BD%AE/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2025/06/10/hello-world/"}],"tags":[{"name":"标签1","slug":"标签1","link":"/tags/%E6%A0%87%E7%AD%BE1/"},{"name":"标签2","slug":"标签2","link":"/tags/%E6%A0%87%E7%AD%BE2/"}],"categories":[{"name":"分类1","slug":"分类1","link":"/categories/%E5%88%86%E7%B1%BB1/"},{"name":"分类2","slug":"分类1/分类2","link":"/categories/%E5%88%86%E7%B1%BB1/%E5%88%86%E7%B1%BB2/"}],"pages":[]}